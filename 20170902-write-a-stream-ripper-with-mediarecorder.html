<!DOCTYPE html><html lang="en-US"><head><meta charSet="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/assets/Inter.css"/><link rel="stylesheet" href="/assets/atom-one-dark.css"/><title>Write a stream ripper with MediaRecorder | BLOG.MY</title><link rel="stylesheet" href="/assets/styles.css"/></head><body><nav><a href="/" class="brand_3">BLOG.MY</a><a href="/about" class="link_4">About</a><a href="/archive" class="link_4 siblingLink_5">Archive</a></nav><hr class="hidden_1"/><h1>Write a stream ripper with MediaRecorder</h1><main><p>The new <a href="https://developer.mozilla.org/docs/Web/API/MediaRecorder" rel="nofollow noopener noreferrer"><code>MediaRecorder</code></a> WebAPI makes media recording super easy.
It allows storing chunks of data from a <a href="https://developer.mozilla.org/docs/Web/API/MediaStream" rel="nofollow noopener noreferrer">media stream</a> as blobs, which can later be concatenated and saved as a single file.
As time passes, more sources of media streams are added.
We can capture media from:</p>
<ul>
<li>Media Devices</li>
<li>Canvas</li>
<li>Media Elements:<ul>
<li><code>&lt;video /&gt;</code></li>
<li><code>&lt;audio /&gt;</code></li>
</ul>
</li>
</ul>
<h2 id="mediastream">MediaStream</h2>
<h3 id="media-devices">Media Devices</h3>
<p>The key component in using <code>MediaRecorder</code> is having access to a MediaStream.
The early uses of MediaStreams came with the use of <code>getUserMedia()</code> method to gain access to local media devices.</p>
<figure><pre class="hljs"><code>navigator.mediaDevices.getUserMedia().then(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">stream</span>) </span>{
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Captured MediaStream:'</span>, stream)
})</code></pre></figure><h3 id="canvas">Canvas</h3>
<p>The <a href="https://developer.mozilla.org/docs/Web/API/HTMLCanvasElement" rel="nofollow noopener noreferrer"><code>&lt;canvas /&gt;</code></a> element implements a method
<a href="https://developer.mozilla.org/docs/Web/API/HTMLCanvasElement/captureStream" rel="nofollow noopener noreferrer"><code>captureStream()</code></a>
that captures content rendered on the canvas element, each time the content changes.</p>
<p>We can supply an optional argument that controls the number of frames recorded per second (FPS).</p>
<figure><pre class="hljs"><code><span class="hljs-comment">// frames recorded only on re-renders</span>
<span class="hljs-keyword">const</span> stream = canvas.captureStream()

<span class="hljs-comment">// 30 frames recorded per second</span>
<span class="hljs-keyword">const</span> stream = canvas.captureStream(<span class="hljs-number">30</span>)</code></pre></figure><p><strong>Note:</strong> To stream returned by <code>canvas.captureStream()</code> is of type <a href="https://developer.mozilla.org/docs/Web/API/CanvasCaptureMediaStream" rel="nofollow noopener noreferrer"><code>CanvasCaptureMediaStream</code></a> and not <code>MediaStream</code>.
This difference will be important later.</p>
<h3 id="media-elements">Media Elements</h3>
<p>In modern browsers, the <code>HTMLMediaElement</code> interface also adds the method
<a href="https://developer.mozilla.org/docs/Web/API/HTMLMediaElement/captureStream" rel="nofollow noopener noreferrer"><code>captureStream()</code></a>
that <em>pipes</em> the media content into a continuous stream.
Since <code>HTMLMediaElement</code> is implemented by both <code>&lt;video /&gt;</code> and <code>&lt;audio /&gt;</code> elements, we can capture media streams from both these elements.</p>
<p>But there&#39;s a difference.
Here, the frames are captured in <em>real time</em>.
If the video being recorded is paused, the frozen frame will be captured repeatedly.</p>
<p><strong>Note:</strong> To use this method in Google Chrome, you need to enable the &quot;Experimental Web Platform features&quot; flag.
You can copy/paste the below for quick access.</p>
<figure><pre class="hljs"><code>chrome://flags/#enable-experimental-web-platform-features</code></pre></figure><h2 id="using-mediarecorder">Using MediaRecorder</h2>
<p>Using the <code>MediaRecorder</code> API is super simple.
Here&#39;s a short snippet that highlights all the key parts.</p>
<figure><pre class="hljs"><code><span class="hljs-comment">// Get a MediaStream object to record</span>
<span class="hljs-comment">// and pass it to MediaRecorder constructor</span>
<span class="hljs-comment">// to create a MediaRecorder instance `recorder`</span>
<span class="hljs-keyword">const</span> stream = mediaElement.captureStream()
<span class="hljs-keyword">const</span> recorder = <span class="hljs-keyword">new</span> MediaRecorder(stream)

<span class="hljs-comment">// When recording starts, the captured frames are emitted</span>
<span class="hljs-comment">// as `dataavailable` events on the `recorder`.</span>
<span class="hljs-comment">// These captured "chunks" can be collected in an array.</span>
<span class="hljs-keyword">const</span> allChunks = []
recorder.ondataavailable = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">e</span>) </span>{
    allChunks.push(e.data)
}

<span class="hljs-comment">// Start recording</span>
recorder.start()

<span class="hljs-comment">// We can pause capturing media and resume again later</span>
<span class="hljs-comment">// to deal with irregular media playback</span>
<span class="hljs-comment">// (likely due to user interactions or buffering)</span>
recorder.pause()
recorder.resume()

<span class="hljs-comment">// When we're done, we can stop recording.</span>
<span class="hljs-comment">// This ensures that no more media chunks are captured,</span>
<span class="hljs-comment">// even if media playback continues.</span>
recorder.stop()

<span class="hljs-comment">// We can now join all the chunks</span>
<span class="hljs-comment">// into a single "blob" ...</span>
<span class="hljs-keyword">const</span> fullBlob = <span class="hljs-keyword">new</span> Blob(allChunks)

<span class="hljs-comment">// ... which we can download using HTML5 `download` attribute on &lt;a /&gt;</span>
<span class="hljs-keyword">const</span> link = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">'a'</span>)
link.style.display = <span class="hljs-string">'none'</span>

<span class="hljs-keyword">const</span> downloadUrl = <span class="hljs-built_in">window</span>.URL.createObjectURL(fullBlob)
link.href = downloadUrl
link.download = <span class="hljs-string">'media.webm'</span>

<span class="hljs-built_in">document</span>.body.appendChild(link)
link.click()
link.remove()</code></pre></figure><h2 id="customising">Customising</h2>
<h3 id="1-media-parameters">1. Media parameters</h3>
<p>The constructor takes an optional argument that can have the following options:</p>
<ul>
<li><code>mimeType</code>: The mime type to use for the recording.</li>
<li><code>audioBitsPerSecond</code>: The bitrate for the audio component of the media.</li>
<li><code>videoBitsPerSecond</code>: The bitrate for the video component of the media.</li>
<li><code>bitsPerSecond</code>: The bitrate for both, the audio and the video components of the media.</li>
</ul>
<p>If <code>bitsPerSecond</code> is provided with one of <code>audioBitsPerSecond</code> or <code>videoBitsPerSecond</code>, it will be applied to the missing one.</p>
<p>Out of them all, <code>mimeType</code> is the most important one.
It controls the codecs used for encoding audio and video components.</p>
<figure><pre class="hljs"><code><span class="hljs-keyword">const</span> codec = <span class="hljs-string">'video/webm'</span>;

<span class="hljs-keyword">const</span> recorder = <span class="hljs-keyword">new</span> MediaRecorder(stream, {
  <span class="hljs-attr">mimeType</span>: codec,
  <span class="hljs-attr">audioBitsPerSecond</span>: <span class="hljs-number">1000000</span> <span class="hljs-comment">// 1 Mbps</span>
  <span class="hljs-attr">bitsPerSecond</span>: <span class="hljs-number">1000000</span>      <span class="hljs-comment">// 2 Mbps</span>
  <span class="hljs-comment">// videoBitsPerSecond will also be 2 Mbps</span>
});</code></pre></figure><p>To check if a codec is supported, use <a href="https://developer.mozilla.org/docs/Web/API/MediaRecorder/isTypeSupported" rel="nofollow noopener noreferrer"><code>MediaRecorder.isTypeSupported()</code></a>.</p>
<figure><pre class="hljs"><code>MediaRecorder.isTypeSupported(<span class="hljs-string">'video/webm'</span>) <span class="hljs-comment">// true</span>
MediaRecorder.isTypeSupported(<span class="hljs-string">'video/mp4'</span>) <span class="hljs-comment">// false</span></code></pre></figure><p>At the time of writing, the supported codecs are:</p>
<figure><pre class="hljs"><code><span class="hljs-comment"># audio codecs</span>
audio/webm
audio/webm;codecs=opus

<span class="hljs-comment"># video codecs</span>
video/webm
video/webm;codecs=avc1

video/webm;codecs=h264
video/webm;codecs=h264,opus

video/webm;codecs=vp8
video/webm;codecs=vp8,opus

video/webm;codecs=vp9
video/webm;codecs=vp9,opus

video/webm;codecs=h264,vp9,opus
video/webm;codecs=vp8,vp9,opus

video/x-matroska
video/x-matroska;codecs=avc1</code></pre></figure><h3 id="2-capturing-time-slices">2. Capturing time slices</h3>
<p>We can pass an optional argument to <code>MediaRecorder.start()</code>.
This is the <code>timeslice</code>.
It is the duration (in milliseconds) of the segment of captured media, emitted in each event.</p>
<p>If not specified, all media captured will be returned in a single Blob.</p>
<h2 id="polyfills">Polyfills</h2>
<p>At the time of writing, the whole <code>MediaRecorder</code> API is <em>bleeding edge</em> and support for <a href="https://developer.mozilla.org/docs/Web/API/HTMLMediaElement/captureStream" rel="nofollow noopener noreferrer"><code>HTMLMediaElement.captureStream()</code></a> is rare.
But there&#39;s a way to make it work.</p>
<p>For capturing audio stream, we can use the <a href="https://developer.mozilla.org/docs/Web/API/Web_Audio_API" rel="nofollow noopener noreferrer">Web Audio API</a>.
There are 3 steps:</p>
<ol>
<li>Create a source node from the media element.</li>
<li>Create a stream destination node.</li>
<li>Connect the source node to the stream destination node.</li>
</ol>
<p>For capturing video stream, we can render a <code>&lt;video /&gt;</code> element onto a <code>&lt;canvas /&gt;</code> element and capture frames from it.</p>
<figure><pre class="hljs"><code><span class="hljs-comment">// audio polyfill</span>

<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">polyfillAudio</span>(<span class="hljs-params">mediaElement</span>) </span>{
    <span class="hljs-keyword">const</span> audioCtx = <span class="hljs-keyword">new</span> AudioContext()

    <span class="hljs-comment">// create a source node and a stream destination node</span>
    <span class="hljs-keyword">const</span> source = audioCtx.createMediaElementSource(mediaElement)
    <span class="hljs-keyword">const</span> destination = audioCtx.createMediaStreamDestination()

    <span class="hljs-comment">// Connect the source node to the stream destination node</span>
    <span class="hljs-comment">// to push audio content into the stream</span>
    source.connect(destination)

    <span class="hljs-comment">// Connect the source node to the audio context's destination node</span>
    <span class="hljs-comment">// so the playback can still deliver audio</span>
    source.connect(audioCtx.destination)

    <span class="hljs-keyword">const</span> audioStream = destination.stream

    <span class="hljs-keyword">return</span> audioStream
}

<span class="hljs-comment">// video polyfill</span>

<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">polyfillVideo</span>(<span class="hljs-params">mediaElement</span>) </span>{
    <span class="hljs-comment">// Create a canvas element</span>
    <span class="hljs-keyword">const</span> canvas = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">'canvas'</span>)

    <span class="hljs-comment">// Start rendering video frames onto the canvas</span>
    renderVideoFrame(canvas, videoElement)

    <span class="hljs-keyword">const</span> videoStream = canvas.captureStream(<span class="hljs-number">60</span>)

    <span class="hljs-keyword">return</span> videoStream
}

<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">renderVideoFrame</span>(<span class="hljs-params">canvas, videoElement</span>) </span>{
    <span class="hljs-keyword">const</span> ctx = canvas.getContext(<span class="hljs-string">'2d'</span>)

    ctx.drawImage(videoElement, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, canvas.width, canvas.height)

    setTimeout(<span class="hljs-function"><span class="hljs-params">()</span> =&gt;</span> renderVideoFrame(canvas, videoElement))
}</code></pre></figure><p>Now we need to do combine the 2 streams and <em>voila!</em></p>
<figure><pre class="hljs"><code><span class="hljs-keyword">const</span> stream = <span class="hljs-keyword">new</span> MediaStream([
    ...audioStream.getTracks(),
    ...videoStream.getTracks(),
])</code></pre></figure><h2 id="rocky-performance">Rocky performance</h2>
<p>There are a few bumps in using <code>MediaRecorder</code>.</p>
<h3 id="1-partial-metadata">1. Partial Metadata</h3>
<p>One serious problem is that the saved recordings have no duration attribute.
To record media, <code>MediaRecorder</code> uses the <a href="https://en.wikipedia.org/wiki/Matroska" rel="nofollow noopener noreferrer">Matroska</a> container format.
The <a href="https://www.matroska.org/technical/specs/index.html" rel="nofollow noopener noreferrer">Matroska format</a> doesn&#39;t treat duration as a mandatory element.</p>
<p>As a result, it is not embedded in the file&#39;s header.</p>
<p>Also, adding it isn&#39;t an easy procedure, nor is it simple - it&#39;s doable, but &quot;takes more than a weekend&quot; kind of doable.</p>
<h3 id="2-adaptive-streaming">2. Adaptive Streaming</h3>
<p>When capturing videos served using <a href="https://developer.mozilla.org/docs/Web/HTML/DASH_Adaptive_Streaming_for_HTML_5_Video" rel="nofollow noopener noreferrer">DASH Adaptive Streaming</a>, changing the resolution causes frame corruption.
I haven&#39;t yet figured out a way to sole this problem, but using the <code>&lt;canvas /&gt;</code> polyfill seems to work just fine.</p>
<p>Here&#39;s a demo video highlighting the 2 problems.</p>
<p><video class="center-block" src="{{site.baseurl}}/media/2017-09-02-mediarecorder/media.webm" controls></video></p>
<h2 id="the-end">The end</h2>
<p>In the future, as browser support for grows, people and organisations alike will start rolling out extensions, plugins and softwares allowing client-side media capturing.
It can be used in an <a href="https://electron.atom.io/apps" rel="nofollow noopener noreferrer">electron apps</a> like camera, video calling, media player.
But for today, it is more or less an niche experimental toy.</p>
<p>At this point, it&#39;d be good to have some <a href="{{site.baseurl}}/gists/2017-09-04-mediarecorder" rel="nofollow noopener noreferrer">demos</a> and the source <a href="https://github.com/zhirzh/zhirzh.github.io/blob/master/gists/2017-09-04-mediarecorder" rel="nofollow noopener noreferrer">code</a>.</p>
</main><footer class="footer_8"><a href="/20171130-cra-apps-with-ssr" class="relatedPosts_9 prevPost_11">⟵ CRA apps with SSR</a><a href="/20170827-tiny-transfers" class="relatedPosts_9 nextPost_10">Tiny Transfers ⟶</a></footer></body></html>