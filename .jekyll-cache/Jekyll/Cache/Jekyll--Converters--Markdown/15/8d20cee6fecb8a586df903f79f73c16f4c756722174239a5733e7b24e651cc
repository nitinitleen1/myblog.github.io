I"9Ž<p>I have published enough Debezium MySQL connector tutorials for taking snapshots from Read Replica. To continue my research I wanted to do something for AWS RDS Aurora as well. But aurora is not using binlog bases replication. So we canâ€™t use the list of tutorials that I published already. In Aurora, we can get the binlog file name and its position from its snapshot of the source Cluster. So I used a snapshot for loading the historical data, and once itâ€™s loaded we can resume the CDC from the main cluster.</p>

<h2 id="requirements">Requirements:</h2>

<ol>
  <li>Running aurora cluster.</li>
  <li>Aurora cluster must have <a href="https://aws.amazon.com/premiumsupport/knowledge-center/enable-binary-logging-aurora/">binlogs enabled</a>.</li>
  <li>Make binlog retention period to a minimum 3 days(its a best practice).</li>
  <li>Debezium connector should be able to access both the clusters.</li>
  <li>Make sure you have different security groups for the main RDS Aurora cluster and the Snapshot cluster.</li>
</ol>

<h2 id="sample-data-in-source-aurora">Sample data in source aurora:</h2>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">create</span> <span class="k">database</span> <span class="n">bhuvi</span><span class="p">;</span>
<span class="n">use</span> <span class="n">bhuvi</span><span class="p">;</span>

<span class="k">create</span> <span class="k">table</span> <span class="n">rohi</span> <span class="p">(</span>
<span class="n">id</span> <span class="nb">int</span><span class="p">,</span>
<span class="n">fn</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="n">ln</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="n">phone</span> <span class="nb">int</span><span class="p">);</span>

<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span></code></pre></figure>

<h2 id="take-aurora-snapshot">Take Aurora snapshot:</h2>

<p>Go to the RDS console and select your source Aurora master node. Take a snapshot of it. Once the snapshot has been done, you see that in the snapshots tab.</p>

<p><img src="/assets/Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot1.jpg" alt="" /></p>

<h2 id="new-cluster-from-snapshot">New cluster from snapshot:</h2>

<p>Then create a new cluster from the snapshot. Once its launched, we can get the binlog info from the logs.</p>

<p>In RDS Console, select the instance name. Click on the Logs &amp; Events tab. Below the Recent events, you can see the binlog information of the source Aurora node while talking the snapshot. This cluster also needs to enable with binlog.</p>

<p><img src="/assets/Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot2.jpg" alt="" /></p>

<h2 id="register-the-mysql-connector">Register the MySQL Connector:</h2>

<p>Follow this link to <a href="https://thedataguy.in/build-production-grade-debezium-with-confluent-kafka-cluster/">configure Kafka cluster and connector.</a> Create a file called <code class="highlighter-rouge">mysql.json</code> and add the Snapshot clusterâ€™s information.</p>

<figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"config"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"connector.class"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.connector.mysql.MySqlConnector"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tasks.max"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.bootstrap.servers"</span><span class="p">:</span><span class="w"> </span><span class="s2">"YOUR-BOOTSTRAP-SERVER:9092"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.topic"</span><span class="p">:</span><span class="w"> </span><span class="s2">"schema-changes.mysql"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.hostname"</span><span class="p">:</span><span class="w"> </span><span class="s2">"SNAPSHOT-INSTANCE-ENDPOINT"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.port"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3306"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.user"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.password"</span><span class="p">:</span><span class="w"> </span><span class="s2">"****"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.whitelist"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"initial"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.locking.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"none"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms"</span><span class="p">:</span><span class="w"> </span><span class="s2">"unwrap"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.add.source.fields"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ts_ms"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tombstones.on.delete"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.transforms.ExtractNewRecordState"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="p">}</span></code></pre></figure>

<p>Run the below command to register it on the connector node.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">curl <span class="nt">-X</span> POST <span class="nt">-H</span> <span class="s2">"Accept: application/json"</span> <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> http://localhost:8083/connectors <span class="nt">-d</span> @mysql.json</code></pre></figure>

<p>Once the snapshot has been done, you can see the snapshot clusterâ€™s current binlog file name and its position in the <code class="highlighter-rouge">connect-offsets</code> topic.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> connect-offsets <span class="nt">--from-beginning</span>

<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000006"</span>,<span class="s2">"pos"</span>:154<span class="o">}</span></code></pre></figure>

<h2 id="add-more-data-on-the-source-cluster">Add more data on the source Cluster:</h2>

<p>To simulate the real production setup, add few more rows to the <code class="highlighter-rouge">rohi</code> table.</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">rohi</span> <span class="k">values</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="s1">'rohit'</span><span class="p">,</span> <span class="s1">'last'</span><span class="p">,</span><span class="mi">87611</span><span class="p">);</span></code></pre></figure>

<p>Also, create a new table.</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="n">use</span> <span class="n">bhuvi</span><span class="p">;</span>
<span class="k">create</span> <span class="k">table</span> <span class="n">testtbl</span> <span class="p">(</span><span class="n">id</span> <span class="nb">int</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">testtbl</span> <span class="k">values</span> <span class="p">(</span><span class="mi">1</span><span class="p">);</span></code></pre></figure>

<p>Because, once we switch to the source cluster, it should read these new data.</p>

<h2 id="update-the-source-aurora-binlog-info">Update the Source Aurora binlog info:</h2>

<p>Stop the connector service and manually inject the binlog information that we got from the Snapshot clusterâ€™s Log &amp; Events section.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">connector-node# systemctl stop confluent-connect-distributed</code></pre></figure>

<p>Get the last read binlog information and its parition from the <code class="highlighter-rouge">connect-offsets</code> topic.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafkacat <span class="nt">-b</span> localhost:9092 <span class="nt">-C</span> <span class="nt">-t</span> connect-offsets  <span class="nt">-f</span> <span class="s1">'Partition(%p) %k %s\\n'</span>

Partition<span class="o">(</span>0<span class="o">)</span> <span class="se">\[</span><span class="s2">"mysql-connector-db01"</span>,<span class="o">{</span><span class="s2">"server"</span>:<span class="s2">"mysql-db01"</span><span class="o">}</span><span class="se">\]</span> <span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000006"</span>,<span class="s2">"pos"</span>:154<span class="o">}</span></code></pre></figure>

<ul>
  <li><code class="highlighter-rouge">kafkacat</code> - command-line utility from confluent.</li>
  <li><code class="highlighter-rouge">-b localhost:9092</code>  - broker details</li>
  <li><code class="highlighter-rouge">-C</code> - Consumer</li>
  <li><code class="highlighter-rouge">-t connect-offsets</code> - topic</li>
  <li><code class="highlighter-rouge">Partition(0)</code> - The partition name where we have the binlog info.</li>
  <li><code class="highlighter-rouge">mysql-connector-db01</code> - connector name</li>
  <li><code class="highlighter-rouge">"server":"mysql-db01</code> - server name we used in <code class="highlighter-rouge">mysql.json</code> file</li>
</ul>

<p>Run the following command to inject the binlog info to the <code class="highlighter-rouge">connect-offsets</code> topic.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nb">echo</span> <span class="s1">'\["mysql-connector-db01",{"server":"mysql-db01"}\]|{"file":"mysql-bin-changelog.000002","pos":2170}'</span> | <span class="se">\\</span>  
kafkacat <span class="nt">-P</span> <span class="nt">-b</span> localhost:9092 <span class="nt">-t</span> connect-offsets <span class="nt">-K</span> | <span class="nt">-p</span> 0</code></pre></figure>

<ul>
  <li><code class="highlighter-rouge">mysql-connector-db01</code> - connector name</li>
  <li><code class="highlighter-rouge">"server":"mysql-db01</code> - server name we used in <code class="highlighter-rouge">mysql.json</code> file</li>
  <li><code class="highlighter-rouge">{"file":"mysql-bin-changelog.000002","pos":2170}</code> - Binlog info from the snapshot clusterâ€™s log.</li>
  <li><code class="highlighter-rouge">kafkacat</code> - command-line utility from confluent.</li>
  <li><code class="highlighter-rouge">-P</code> - Producer</li>
  <li><code class="highlighter-rouge">-b localhost:9092</code>  - broker details</li>
  <li><code class="highlighter-rouge">-t connect-offsets</code> - topic</li>
  <li><code class="highlighter-rouge">-p 0</code> Partition where we have the binlog info.</li>
</ul>

<p>Now if you read the data from the consumer, itâ€™ll show the new binlog.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> connect-offsets <span class="nt">--from-beginning</span>

<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000006"</span>,<span class="s2">"pos"</span>:154<span class="o">}</span>
<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000002"</span>,<span class="s2">"pos"</span>:2170<span class="o">}</span></code></pre></figure>

<h2 id="switch-to-source-cluster">Switch to Source Cluster:</h2>

<p>Before doing the switchover, we need to make that the connector should not access to the snapshot cluster once the connector service started. We can achieve this in 2 ways.</p>

<ol>
  <li>Anyhow, we read all the from the snapshot cluster, so delete it.</li>
  <li>In the Snapshot clusterâ€™s security group, remove the connectorâ€™s node IP.</li>
</ol>

<p>I recommend using the 2nd option. Now start the connector service. After a few seconds, you can see the logs like below.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="se">\[</span>2020-01-02 06:57:21,448<span class="se">\]</span> INFO Starting MySqlConnectorTask with configuration: <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,450<span class="se">\]</span> INFO    connector.class <span class="o">=</span> io.debezium.connector.mysql.MySqlConnector <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,450<span class="se">\]</span> INFO    snapshot.locking.mode <span class="o">=</span> none <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,451<span class="se">\]</span> INFO    tasks.max <span class="o">=</span> 1 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,451<span class="se">\]</span> INFO    database.history.kafka.topic <span class="o">=</span> replica-schema-changes.mysql <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,452<span class="se">\]</span> INFO    transforms <span class="o">=</span> unwrap <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,452<span class="se">\]</span> INFO    internal.key.converter.schemas.enable <span class="o">=</span> <span class="nb">false</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,452<span class="se">\]</span> INFO    transforms.unwrap.add.source.fields <span class="o">=</span> ts_ms <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    tombstones.on.delete <span class="o">=</span> <span class="nb">false</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    transforms.unwrap.type <span class="o">=</span> io.debezium.transforms.ExtractNewRecordState <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    value.converter <span class="o">=</span> org.apache.kafka.connect.json.JsonConverter <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.whitelist <span class="o">=</span> bhuvi <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    key.converter <span class="o">=</span> org.apache.kafka.connect.json.JsonConverter <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.user <span class="o">=</span> admin <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.server.id <span class="o">=</span> 1 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.history.kafka.bootstrap.servers <span class="o">=</span> 172.31.40.132:9092 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.server.name <span class="o">=</span> mysql-db01 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,453<span class="se">\]</span> INFO    database.port <span class="o">=</span> 3306 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    key.converter.schemas.enable <span class="o">=</span> <span class="nb">false</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    internal.key.converter <span class="o">=</span> org.apache.kafka.connect.json.JsonConverter <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    task.class <span class="o">=</span> io.debezium.connector.mysql.MySqlConnectorTask <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    database.hostname <span class="o">=</span> snapshot-cluster.cluster-chbcar19iy5o.us-east-1.rds.amazonaws.com <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    database.password <span class="o">=</span> <span class="k">********</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    internal.value.converter.schemas.enable <span class="o">=</span> <span class="nb">false</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    name <span class="o">=</span> mysql-connector-db01 <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    value.converter.schemas.enable <span class="o">=</span> <span class="nb">false</span> <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    internal.value.converter <span class="o">=</span> org.apache.kafka.connect.json.JsonConverter <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,454<span class="se">\]</span> INFO    snapshot.mode <span class="o">=</span> initial <span class="o">(</span>io.debezium.connector.common.BaseSourceTask<span class="o">)</span>
<span class="se">\[</span>2020-01-02 06:57:21,512<span class="se">\]</span> INFO <span class="se">\[</span>Producer <span class="nv">clientId</span><span class="o">=</span>connector-producer-mysql-connector-db01-0<span class="se">\]</span> Cluster ID: H-jsdNk9SUuud35n3AIk8g <span class="o">(</span>org.apache.kafka.clients.Metadata<span class="o">)</span></code></pre></figure>

<h3 id="update-the-endpoint">Update the Endpoint:</h3>

<p>Create an updated config file which has the endpoint of Source Aurora endpoint and the <code class="highlighter-rouge">snapshot mode = schema only recovery</code> .</p>

<p>And the main important thing is use a different topic for schema changes history. Else youâ€™ll end up with some error like below.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">ERROR Failed due to error: Error processing binlog event <span class="o">(</span>io.debezium.connector.mysql.BinlogReader<span class="o">)</span>
org.apache.kafka.connect.errors.ConnectException: Encountered change event <span class="k">for </span>table bhuvi.rohi whose schema isn<span class="s1">'t known to this connector</span></code></pre></figure>

<p>File: mysql-update.json</p>

<figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
</span><span class="nl">"connector.class"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.connector.mysql.MySqlConnector"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.locking.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"none"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tasks.max"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.topic"</span><span class="p">:</span><span class="w"> </span><span class="s2">"schema-changes.mysql"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms"</span><span class="p">:</span><span class="w"> </span><span class="s2">"unwrap"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.add.source.fields"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ts_ms"</span><span class="p">,</span><span class="w">
</span><span class="nl">"tombstones.on.delete"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"transforms.unwrap.type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"io.debezium.transforms.ExtractNewRecordState"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.whitelist"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bhuvi"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.user"</span><span class="p">:</span><span class="w"> </span><span class="s2">"admin"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.history.kafka.bootstrap.servers"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BROKER-NODE-IP:9092"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.server.name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.port"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3306"</span><span class="p">,</span><span class="w">
</span><span class="nl">"key.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.key.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.hostname"</span><span class="p">:</span><span class="w"> </span><span class="s2">"SOURCE-AURORA-ENDPOINT"</span><span class="p">,</span><span class="w">
</span><span class="nl">"database.password"</span><span class="p">:</span><span class="w"> </span><span class="s2">"*****"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mysql-connector-db01"</span><span class="p">,</span><span class="w">
</span><span class="nl">"value.converter.schemas.enable"</span><span class="p">:</span><span class="w"> </span><span class="s2">"false"</span><span class="p">,</span><span class="w">
</span><span class="nl">"internal.value.converter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"org.apache.kafka.connect.json.JsonConverter"</span><span class="p">,</span><span class="w">
</span><span class="nl">"snapshot.mode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"SCHEMA_ONLY_RECOVERY"</span><span class="w">
</span><span class="p">}</span></code></pre></figure>

<p>Run the below command to update the  MySQL connector.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">curl <span class="nt">-X</span> PUT <span class="nt">-H</span> <span class="s2">"Accept: application/json"</span> <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> http://localhost:8083/connectors/mysql-connector-db01/config <span class="nt">-d</span> @mysql-update.json</code></pre></figure>

<p>Then immediately itâ€™ll start reading from the Source Aurora cluster from the binlog position <code class="highlighter-rouge">mysql-bin-changelog.000002 2170</code></p>

<p>You can see these changes from the <code class="highlighter-rouge">connect-offsets</code> topic.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> connect-offsets <span class="nt">--from-beginning</span>

<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000006"</span>,<span class="s2">"pos"</span>:154<span class="o">}</span>
<span class="o">{</span><span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000002"</span>,<span class="s2">"pos"</span>:2170<span class="o">}</span>
<span class="o">{</span><span class="s2">"ts_sec"</span>:1577948351,<span class="s2">"file"</span>:<span class="s2">"mysql-bin-changelog.000003"</span>,<span class="s2">"pos"</span>:1207,<span class="s2">"row"</span>:1,<span class="s2">"server_id"</span>:2115919109,<span class="s2">"event"</span>:2<span class="o">}</span></code></pre></figure>

<p>And we add 2 more rows to the rohi table. You can see those new values from  the <code class="highlighter-rouge">bhuvi.rohi</code> topic.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-console-consumer <span class="nt">--bootstrap-server</span> localhost:9092 <span class="nt">--topic</span> mysql-db01.bhuvi.rohi <span class="nt">--from-beginning</span>
<span class="o">{</span><span class="s2">"id"</span>:1,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:2,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:3,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:4,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:5,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:0<span class="o">}</span>

<span class="o">{</span><span class="s2">"id"</span>:6,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:1577948298000<span class="o">}</span>
<span class="o">{</span><span class="s2">"id"</span>:7,<span class="s2">"fn"</span>:<span class="s2">"rohit"</span>,<span class="s2">"ln"</span>:<span class="s2">"last"</span>,<span class="s2">"phone"</span>:87611,<span class="s2">"__ts_ms"</span>:1577948304000<span class="o">}</span></code></pre></figure>

<p>Also, you can the new table <code class="highlighter-rouge">testtbl</code> added to the topic.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kafka-topics <span class="nt">--zookeeper</span> localhost:2181 <span class="nt">--list</span>

connect-configs
connect-offsets
connect-status
default_ksql_processing_log
mysql-db01
mysql-db01.bhuvi.rohi
mysql-db01.bhuvi.testtbl
replica-schema-changes.mysql
schema-changes.mysql</code></pre></figure>

<h3 id="debezium-series-blogs">Debezium Series blogs:</h3>

<ol>
  <li><a href="https://thedataguy.in/build-production-grade-debezium-with-confluent-kafka-cluster/">Build Production Grade Debezium Cluster With Confluent Kafka</a></li>
  <li><a href="https://thedataguy.in/monitor-debezium-mysql-connector-with-prometheus-and-grafana/">Monitor Debezium MySQL Connector With Prometheus And Grafana</a></li>
  <li><a href="https://thedataguy.in/debezium-mysql-snapshot-from-read-replica-with-gtid/">Debezium MySQL Snapshot From Read Replica With GTID</a></li>
  <li><a href="https://thedataguy.in/debezium-mysql-snapshot-from-read-replica-and-resume-from-master/">Debezium MySQL Snapshot From Read Replica And Resume From Master</a></li>
  <li><a href="https://thedataguy.in/debezium-mysql-snapshot-for-aws-rds-aurora-from-backup-snaphot/">Debezium MySQL Snapshot For AWS RDS Aurora From Backup Snaphot</a></li>
  <li><a href="https://medium.com/searce/realtime-cdc-from-mysql-using-aws-msk-with-debezium-28da5a4ca873">RealTime CDC From MySQL Using AWS MSK With Debezium</a></li>
</ol>
:ET